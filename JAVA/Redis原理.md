## 数据结构
### 简单动态字符串SDS
header：len（字符串长度），alloc（buf申请的长度/字节数，不包含结束标示/0），flags（不同头类型用来控制SDS头的大小）
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728144100176.png)

**内存预分配**：追加字符串会首先申请新内存空间：新字符串小于1M，则新空间 为 扩展后字符串长度的两倍+1；大于1M，新空间：字符串长度+1M+1
申请内存的时候需要和linux的内核交互，这个操作非常消耗资源
- 优点
	- 获取字符串长度的时间复杂度为O（1）
	- 支持动态扩容
	- 减少内存分配次数
	- 二进制安全
### IntSet
Redis中set集合 的一种实现方式，基于整数数组来实现，具备长度可变，有序等特征 
数组本身是一个指针，指向起始元素的地址 ，是连续内存空间。contents指向数组第一个元素的地址
**set值必须是2^n**
- **支持动态升级**：添加的数字超出int16_t范围，insert会自动升级编码方式，为int32，每个整数占4个字节。按照心电编码方式及元素个数扩容数组；**倒序**依次将数组中的元素拷贝到扩容后的正确位置（防止覆盖）；encouding属性改变，length属性改变
- 底层采用二分查找来查询
- 元素唯一有序
- ![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728150505702.png)
### Dict
键和值的映射关系通过dict来实现
组成：哈希表，哈希节点，字典
类似java 的HashTable，底层是数组加链表来解决哈希冲突
Dict包含两个哈希表，ht[ 0 ]平常用，ht[1]用来rehash
添加键值对：**头插法**，**与运算**
	在链表头部插入新节点。新节点总是成为头节点；插入的时间复杂度为O（1）
		头插法的实现
			![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728151903809.png)

字典结构：
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728151632288.png)

扩容：dict在每次新增键值对时都会检查负载因子（LoadFactor = used/size）
	触发的两种情况：1. 负载因子≥1，且服务器没有执行bgsave或者bgrewriteaof等后台进程；2. 负载子>5
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728153203914.png)
收缩：删除元素时对负载因子做检查，小于0.1做收缩

渐进式rehash  
	rehash过程：
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728154445169.png)
	渐进式rehash流程：
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728154215016.png)

### ZipList
特殊的“双端链表”，有一系列特殊编码的**连续**内存块组成。
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728161222170.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728161241761.png)


![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728160743040.png)
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728161334985.png)
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728161802624.png)

连锁更新问题

### QuickList
双端链表，每个节点都是一个ZipList
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728163341877.png)
### SkipList
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728165040147.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728165109938.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728165129205.png)
### RedisObject
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728165928164.png)
### String
最好使用整数，或者小于44字节，因为raw需要申请两次内存
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728171236470.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728171330417.png)

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728171315186.png)

### List
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728172407690.png)

### Set
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728192626160.png)
### ZSet
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728193132155.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728195318216.png)




## 网络模型

ubuntu和Centos 都是Linux的发行版，发行版可以看成对linux包了一层壳，任何Linux发行版，其系统内核都是Linux。我们的**应用都需要通过Linux内核与硬件交互**。

用户的应用，比如redis，mysql等其实是没有办法去执行访问我们操作系统的硬件的，所以我们可以**通过发行版的这个壳子去访问内核，再通过内核去访问计算机硬件**。

计算机硬件包括，如cpu，内存，网卡等等，内核（通过寻址空间）可以操作硬件的，但是**内核需要不同设备的驱动**，有了这些驱动之后，内核就可以去对计算机硬件去进行 内存管理，文件系统的管理，进程的管理等等。

我们想要用户的应用来访问，计算机就必须要通过对外暴露的一些**接口**，才能访问到，从而实现对内核的操控，但是**内核本身上来说也是一个应用**，所以他本身也**需要一些内存，cpu等设备资源**，用户应用本身也在消耗这些资源，如果不加任何限制，用户去操作随意的去操作我们的资源，就有可能导致一些冲突，甚至有可能导致我们的系统出现无法运行的问题，因此我们需要把用户和**内核隔离开**。

进程的寻址空间划分成两部分：**内核空间、用户空间**

什么是寻址空间呢？我们的应用程序也好，还是内核空间也好，都是没有办法直接去物理内存的，而是通过**分配一些虚拟内存映射到物理内存中**，我们的内核和应用程序去访问虚拟内存的时候，就需要一个虚拟地址，这个地址是一个无符号的整数，比如一个32位的操作系统，他的带宽就是32，他的虚拟地址就是2的32次方，也就是说他**寻址的范围**就是0~2的32次方， 这片**寻址空间对应的**就是2的32个字节，就是4GB，这个4GB，会有3个GB分给**用户空间**，会有1GB给**内核系统**。

在linux中，他们权限分成两个等级，0和3，**用户空间只能执行受限的命令**（Ring3），而且不能直接调用系统资源，必须通过内核提供的接口来访问内核空间可以执行特权命令（Ring0），调用一切系统资源，所以一般情况下，**用户的操作是运行在用户空间，而内核运行的数据是在内核空间**的，而有的情况下，一个应用程序需要去调用一些特权资源，去调用一些内核空间的操作，所以此时他俩需要在用户态和内核态之间进行切换。

Linux系统为了**提高IO效率**，会在用户空间和内核空间都加入**缓冲区**：
写数据时，要把用户缓冲数据拷贝到内核缓冲区，然后写入设备
读数据时，要从设备读取数据到内核缓冲区，然后拷贝到用户缓冲区

针对这个操作：我们的用户在写读数据时，会去向内核态申请，想要读取内核的数据，而内核数据要去等待驱动程序从硬件上读取数据，当从磁盘上加载到数据之后，内核会将数据写入到内核的缓冲区中，然后再将数据拷贝到用户态的buffer中，然后再返回给应用程序，整体而言，速度慢，就是这个原因，为了加速，我们希望read也好，还是wait for data也最好都不要等待，或者时间尽量的短。

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728201432402.png)

### **阻塞IO（Blocking IO）**
整个过程中，用户**从发起读请求开始，一直到读取到数据，都是一个阻塞状态**。

用户去读取数据时，会去先发起**recvform**一个命令，去尝试从内核上加载数据，如果内核没有数据，那么用户就会**等待**，此时内核会去从硬件上读取数据，内核读取数据之后，会把数据拷贝到用户态，拷贝过程中，用户进程依然**阻塞等待**，拷贝完成，用户进程解除阻塞，并且返回ok，整个过程，都是阻塞等待的，

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728205804905.png)


### **非阻塞IO（Nonblocking IO）**

非阻塞IO的**recvfrom操作会立即返回结果而不是阻塞用户进程**。

非阻塞IO模型中，用户进程在第一个阶段是非阻塞，第二个阶段是阻塞状态。虽然是非阻塞，但性能并没有得到提高。而且**忙等机制会导致CPU空转，CPU使用率暴增**。

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728205727122.png)

### **==IO多路复用==**（IO Multiplexing）

**IO多路复用**是**利用单个线程来同时监听多个FD**，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728210936003.png)

**select**允许用户程序一次性监听多个文件描述符（如套接字），减少无效等待，避免忙轮询

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728210649115.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728210800128.png)


**select**是Linux最早是由的I/O多路复用技术：
把需要处理的数据**封装成FD**，然后在用户态时创建一个fd的集合（这个集合的大小是要监听的那个FD的最大值+1，但是大小整体是有限制的 ），这个集合的长度大小是有限制的，同时在这个集合中，标明出来我们要控制哪些数据。

执行select函数，将整个fd发给内核态，内核态会去遍历用户态传递过来的数据，如果发现这里边的数据都没有就绪，就休眠，直到有数据准备好时，就会被唤醒，唤醒之后，再次遍历一遍，处理掉没有准备好的数据，最后再将这个FD集合写回到用户态中去。
用户态并不知道谁处理好了，所以需要遍历，找到对应准备好数据的节点，再去发起读请求。

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728211854876.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728212334857.png)

### IO多路复用-epoll
**epoll模式**是对select和poll的改进，它提供了三个函数：

第一个是：**eventpoll的函数**，他内部包含两个东西
1、**红黑树**-> 记录的事要监听的FD
2、一个是**链表**->一个链表，记录的是就绪的FD

第二个调用**epoll_ctl**操作，将要监听的数据添加到红黑树上去，并且给每个fd设置一个监听函数，这个函数会在fd数据就绪时触发，就是准备好了，现在就把fd把数据添加到list_head中去

第三个调用**epoll_wait**函数
就去等待，在**用户态创建一个空的events数组**，当就绪之后，我们的回调函数会**把数据添加到list_head中**去，当调用这个函数的时候，会去检查list_head，当然这个过程需要参考配置的等待时间，可以等一定时间，也可以一直等， 如果在此过程中，检查到了list_head中有数据会将数据添加到链表中，此时将数据放入到events数组中，并且返回对应的操作的数量，用户态的此时收到响应后，从events中拿到对应准备好的数据的节点，再去调用方法去拿数据。

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728214253802.png)

**==小总结：==**

select模式存在的三个问题：
* 能监听的FD最大不超过1024
* 每次select都需要把所有要监听的FD都拷贝到内核空间
* 每次都要遍历所有FD来判断就绪状态

poll模式的问题：
* poll利用链表解决了select中监听FD上限的问题，但依然要遍历所有FD，如果监听较多，性能会下降

**epoll模式**中如何解决这些问题的？
* 基于epoll实例中的红黑树保存要监听的FD，**理论上无上限**，而且**增删改查效率都非常高**
* 每个FD只需要执行一次epoll_ctl添加到红黑树，以后每次epol_wait无需传递任何参数，**无需重复拷贝**FD到内核空间
* 利用ep_poll_callback机制来监听FD状态，**无需遍历所有FD**，因此性能不会随监听的FD数量增多而下降
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728214112232.png)
### ET，LT
当FD有数据可读时，我们调用epoll_wait（或者select、poll）可以得到通知。但是**事件通知的模式**有两种：
* LevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知。
* EdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知。
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728215223611.png)
如果我们采用LT模式，因为FD中仍有1kb数据，则第⑤步依然会返回结果，并且得到通知
如果我们采用ET模式，因为第③步已经消费了FD可读事件，第⑤步FD状态没有变化，因此epoll_wait不会返回，数据无法读取，客户端响应超时。

### 基于epoll的服务器端流程

服务器启动以后，**服务端会去调用epoll_create**，创建一个**epoll实例**，epoll实例中包含两个数据

1、红黑树（为空）：rb_root 用来去记录**需要被监听的FD**
2、链表（为空）：list_head，用来存放**已经就绪的FD**

创建好了之后，会去**调用epoll_ctl函数**，此函数会会**将需要监听的数据添加到rb_root**中去，并且对当前这些存在于红黑树的节点设置回调函数，当这些被监听的数据一旦准备完成，就会被调用，而**调用的结果就是将红黑树的fd添加到list_head中**去(但是此时并没有完成)

3、当第二步完成后，就会**调用epoll_wait函数**，这个函数会去校验是否有数据准备完毕（因为数据一旦准备就绪，就会被回调函数添加到list_head中），在等待了一段时间后(可以进行配置)，如果等够了超时时间，则返回没有数据，如果有，则进一步判断当前是什么事件，如果是建立连接时间，则**调用accept() 接受客户端socket**，拿到建立连接的socket，然后建立起来连接，如果是其他事件，则把数据进行写出
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728215758345.png)

### 信号驱动IO

信号驱动IO是**与内核建立SIGIO的信号关联并设置回调**，当内核有FD就绪时，会**发出SIGIO信号通知用户**，期间用户应用可以执行其它业务，**无需阻塞等待**。

阶段一：

* 用户进程调用sigaction，注册信号处理函数
* 内核返回成功，开始监听FD
* 用户进程不阻塞等待，可以执行其它业务
* 当内核数据就绪后，回调用户进程的SIGIO处理函数

阶段二：

* 收到SIGIO回调信号
* 调用recvfrom，读取
* 内核将数据拷贝到用户空间
* 用户进程处理数据

当有大量IO操作时，信号较多，SIGIO处理函数不能及时处理可能导致信号队列溢出，而且内核空间与用户空间的频繁信号交互性能也较低。
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728220023229.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728220141878.png)
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728220342815.png)
	核心业务是单线程，命令处理是单线程
	删除bigKey可能会导致主线程阻塞，耗时久，因此采用一种异步删除的方法，通过后台另一个线程去删除
	集群会引入其他问题，搭建复杂
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728221216146.png)

![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250728220817847.png)

### Redis是单线程的吗？为什么使用单线程

Redis 采用单线程模型（主要指 **核心网络I/O和键值操作** 的单线程，而非整个Redis进程）的设计是权衡多种因素后的结果，尤其在早期版本中，这种设计带来了显著的优点，但也随着发展逐渐引入了多线程优化。以下是详细原因：

**为什么Redis要选择单线程？**

* 抛开持久化不谈，Redis是纯  内存操作，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来巨大的性能提升。
* 多线程会导致过多的上下文切换，带来不必要的开销
* 引入多线程会面临线程安全问题，必然要引入线程锁这样的安全手段，实现复杂度增高，而且性能也会大打折扣

#### **1. 避免锁竞争和上下文切换**

- **无锁设计**：单线程避免了多线程的锁竞争问题，简化了数据结构的实现（如内存分配、哈希表操作），无需考虑并发修改，提升了代码的可维护性和执行效率。
    
- **减少CPU开销**：多线程的上下文切换（Context Switching）会消耗CPU资源，单线程模型可以完全避免这一开销，尤其在CPU密集型场景下更高效。
    

---

#### **2. 基于内存操作，CPU通常不是瓶颈**

- Redis 的操作主要基于内存，速度极快（微秒级），而网络I/O（如客户端请求）或持久化操作（如RDB/AOF）才是主要延迟来源。单线程已足以饱和网络带宽或内存吞吐。
    
- 在大多数场景下，Redis 的性能瓶颈在于 **网络延迟** 或 **内存带宽**，而非CPU计算能力。
    

---

#### **3. 原子性操作的天然优势**

- 单线程使得所有命令天然具备原子性，无需额外同步机制（如事务、Lua脚本）即可保证操作串行执行，简化了开发者的并发控制。
    

---

#### **4. 简化设计和维护**

- 单线程模型代码更简单，减少了线程安全问题的复杂性（如竞态条件、死锁），降低了维护成本。
    

---

#### **5. 高效的事件驱动模型（I/O多路复用）**

- Redis 使用 **epoll/kqueue** 等系统调用实现非阻塞I/O多路复用，单线程可以高效处理数万并发连接，性能不逊于多线程。
    
- 通过事件循环（Event Loop），单线程能顺序处理多个客户端的请求，而非依赖多线程并发。
    

---

#### **为什么后来引入多线程？**

Redis 在后续版本中逐步引入多线程优化，但**核心操作仍保持单线程**：

- **Redis 4.0**：后台线程处理异步任务（如AOF刷盘、Key删除）。
    
- **Redis 6.0+**：支持多线程处理网络I/O（读取请求和写回响应），但命令执行仍是单线程，延续了原子性优势。在核心网络模型中引入 多线程，进一步提高对于多核CPU的利用率
    

---

#### **适用场景的权衡**

- **适合单线程的场景**：高吞吐、低延迟的键值操作，并发连接数多但每个请求耗时短。
    
- **不适合的场景**：需要并行计算或CPU密集型任务（如复杂数据分析），此时可考虑其他数据库或配合多实例分片。
    

---

#### **总结**

Redis 的单线程设计以 **简单性、高性能和低延迟** 为核心，通过事件驱动和内存操作最大化利用单线程能力。而多线程的引入是为了进一步优化特定场景（如网络I/O），核心逻辑仍保持单线程以避免复杂性。这种设计哲学使得 Redis 在大多数场景下成为高效的缓存和存储解决方案。

## **多线程的潜在问题**

### **(1) 锁竞争（Lock Contention）**

- 多线程并发访问共享数据（如内存中的哈希表）时，必须使用锁（如互斥锁、读写锁）来保证线程安全。
    
- **问题**：
    
    - **锁竞争**：高并发时，线程可能频繁争抢锁，导致性能下降（如自旋锁消耗CPU）。
        
    - **死锁风险**：不合理的锁顺序可能导致多个线程互相等待，形成死锁。
        

### **(2) 上下文切换（Context Switching）开销**

- **什么是上下文切换？**  
    当 CPU 从一个线程切换到另一个线程时，需要保存当前线程的状态（寄存器、程序计数器等），并恢复目标线程的状态，这个过程称为**上下文切换**。
    
- **问题**：
    
    - **CPU 时间浪费**：频繁切换会消耗大量 CPU 时间在调度上，而非实际任务执行。
        
    - **缓存失效**：线程切换可能导致 CPU 缓存（L1/L2/L3）失效，降低缓存命中率，拖慢执行速度。
        

### **(3) 数据一致性与原子性问题**

- 多线程环境下，即使使用锁，仍然可能遇到：
    
    - **竞态条件（Race Condition）**：多个线程同时修改数据，导致结果不符合预期。
        
    - **内存可见性问题**：由于 CPU 缓存不一致，一个线程的修改可能不会立即被其他线程看到（需使用内存屏障或原子操作）。
        

### **(4) 调试和维护困难**

- 多线程程序的 Bug（如死锁、数据竞争）难以复现和调试，增加了开发和维护成本。

---

|**场景**|**单线程（Redis 核心）**|**多线程（如 MySQL、Java 应用）**|
|---|---|---|
|**CPU 密集型**|不适合（计算任务阻塞主线程）|适合（利用多核并行计算）|
|**I/O 密集型**|适合（epoll 高并发连接）|适合（异步 I/O + 线程池）|
|**锁竞争**|无锁，无竞争|需处理锁竞争、死锁问题|
|**原子性**|天然保证|需额外同步机制（锁、CAS）|
|**适用场景**|缓存、高速读写|复杂事务、计算任务|

---

**单线程Redis网络模型**
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250729145141007.png)
多线程部分
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250729150554682.png)

## 通信协议

Redis**通信**一般分两步（不包括pipeline和PubSub）：
1. 客户端向服务端发送一条命令，
2. 服务端解析并执行命令，返回响应结果给客户端。
客户端发送命令的格式，服务端响应结果的格式有一个规范：**通信协议RESP** （默认 2.0，Redis6.0升级的3.0版本增加了更多数据类型并且支持6.0的新特性--客户端缓存

在RESP中,通过首字节的字符来区分不同数据类型,常用的**数据类型**包括5种:

◆**单行字符串**:首字节是‘==**+**==’,后面跟上单行字符串,以CRLF(“\r\n")结尾。例如返回"OK":"+OK\r\n"

◆错误(Errors):首字节是‘==**-**==',与单行字符串格式一样,只是字符串是异常信息,例如:"-Error message\r\n"

◆数值:首字节是‘==**:**==’,后面跟上数字格式的字符串,以CRLF结尾。例如:":10\r\n"

◆**多行字符串**:首字节是‘==$==’,表示二进制安全的字符串,最大支持512MB:
	◆ 如果大小为0,则代表空字符串:"$0\r\n\r\n"
	◆ 如果大小为-1,则代表不存在:"$-1\r\n"

◆**数组**:首字节是==‘ * ==’ , 后面跟上数组元素个数,再跟上元素,元素数据类型不限:
![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250729153105517.png)

## 内存策略

**RedisKey的TTL记录方式：**
在RedisDB中通过一个Dict记录每个Key的TTL时间

**过期key的删除策略：**

1. 惰性清理：每次查找key时判断是否过期，如果过期则删除
2. 定期清理：定期抽样部分key，判断是否过期，如果过期则删除。
	定期清理的两种模式：
	SLOW模式执行频率默认为10，每次不超过25ms
	FAST模式执行频率不固定，但两次间隔不低于2ms，每次耗时不超过1ms

内存过期
	在Redis的database结构体中，有两个Dict：一个用来记录key-value；另一个用来记录key-TTL。
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250729172820159.png)
	![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250729172717551.png)

**Redis是如何知道一个key是否过期呢？
：利用两个Dict分别记录key-value对及key-ttl对**

**是不是TTL到期就立即删除了呢？**
**惰性删除**：在访问一个key的时候，检查该key的存活时间，如果已经过期才执行删除。
**周期删除**：通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。
	执行周期有两种：
	Redis服务初始化函数initServer()中设置定时任务，按照server.hz的频率来执行过期key清理，模式为SLOW
	Redis的每个事件循环前会调用beforeSleep()函数，执行过期key清理，模式为FAST

*SLOW模式规则*：
* 执行频率受server.hz影响，默认为10，即每秒执行10次，每个执行周期100ms。
* 执行清理耗时不超过一次执行周期的25%.默认slow模式耗时不超过25ms
* 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期
* 如果没达到时间上限（25ms）并且过期key比例大于10%，再进行一次抽样，否则结束

*FAST模式规则*（过期key比例小于10%不执行 ）：
* 执行频率受beforeSleep()调用频率影响，但两次FAST模式间隔不低于2ms
* 执行清理耗时不超过1ms
* 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期
* 如果没达到时间上限（1ms）并且过期key比例大于10%，再进行一次抽样，否则结束


**内存淘汰**：就是当Redis内存使用达到设置的上限时，主动挑选部分key删除以释放更多内存的流程。Redis会在处理客户端命令的方法processCommand()中尝试做内存淘汰：

Redis支持8种不同策略来选择要删除的key：

* noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。
* volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰
* allkeys-random：对全体key ，随机进行淘汰。也就是直接从db->dict中随机挑选
* volatile-random：对设置了TTL的key ，随机进行淘汰。也就是从db->expires中随机挑选。
* allkeys-lru： 对全体key，基于LRU算法进行淘汰
* volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰
* allkeys-lfu： 对全体key，基于LFU算法进行淘汰
* volatile-lfu： 对设置了TTL的key，基于LFI算法进行淘汰


  比较容易混淆的有两个：
  * LRU（Least Recently Used），最少最近使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。
  * LFU（Least Frequently Used），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。

LFU的访问次数之所以叫做逻辑访问次数，是因为并不是每次key被访问都计数，而是通过运算：

* 生成0~1之间的随机数R
* 计算 (旧次数 * lfu_log_factor + 1)，记录为P
* 如果 R < P ，则计数器 + 1，且最大不超过255
* 访问次数会随时间衰减，距离上一次访问时间每隔 lfu_decay_time 分钟，计数器 -1


![image.png](https://kmk1132-obs-1370539359.cos.ap-guangzhou.myqcloud.com/20250729161905893.png)
